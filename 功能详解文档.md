# 智能多语言视频语音转换系统 - 功能详解文档

## 功能模块技术详解

### 1. 音频提取模块 (generateWav.py)

#### 技术原理
音频提取是整个系统的第一步，负责从视频文件中分离出音频轨道。

#### 实现技术
- **核心库：** MoviePy (基于FFmpeg)
- **音频格式：** WAV (无损格式，便于后续处理)
- **编码参数：** PCM 16位，16kHz采样率，单声道

#### 具体实现逻辑
```python
def extract_audio(video_path, output_path):
    # 1. 加载视频文件
    video = VideoFileClip(video_path)
    
    # 2. 检查是否有音频轨道
    if video.audio is None:
        raise Exception("视频文件不包含音频轨道")
    
    # 3. 提取音频并设置参数
    audio = video.audio
    audio = audio.set_fps(16000)  # 设置采样率
    
    # 4. 保存为WAV格式
    audio.write_audiofile(output_path, codec='pcm_s16le')
    
    # 5. 释放资源
    video.close()
    audio.close()
```

#### 关键技术点
1. **内存管理：** 及时释放VideoFileClip对象避免内存泄漏
2. **错误处理：** 检测音频轨道存在性，处理损坏文件
3. **格式统一：** 转换为标准采样率，便于API识别
4. **路径处理：** 使用绝对路径，避免中文路径问题

#### 优化策略
- 预先检查文件完整性
- 使用临时文件避免覆盖原文件
- 支持多种视频格式输入

---

### 2. 语音识别模块 (video_to_txt.py)

#### 技术原理
使用科大讯飞实时语音转写API，通过WebSocket协议实现流式语音识别。

#### 实现技术
- **API提供商：** 科大讯飞 (iFlytek)
- **通信协议：** WebSocket
- **认证方式：** HMAC-SHA256签名
- **数据格式：** JSON + Base64音频数据

#### 具体实现逻辑
```python
class WebSocketSTT:
    def __init__(self, appid, api_key, api_secret):
        self.appid = appid
        self.api_key = api_key
        self.api_secret = api_secret
        self.ws_url = "wss://iat-api.xfyun.cn/v2/iat"
    
    def create_auth_url(self):
        """创建认证URL"""
        # 1. 生成时间戳
        date = datetime.utcnow().strftime('%a, %d %b %Y %H:%M:%S GMT')
        
        # 2. 构建签名字符串
        signature_origin = f"host: iat-api.xfyun.cn\ndate: {date}\nGET /v2/iat HTTP/1.1"
        
        # 3. 生成HMAC-SHA256签名
        signature_sha = hmac.new(
            self.api_secret.encode('utf-8'),
            signature_origin.encode('utf-8'),
            digestmod=hashlib.sha256
        ).digest()
        signature_sha = base64.b64encode(signature_sha).decode(encoding='utf-8')
        
        # 4. 构建认证URL
        authorization = f'api_key="{self.api_key}", algorithm="hmac-sha256", headers="host date request-line", signature="{signature_sha}"'
        return self.ws_url + '?' + urlencode(params)
    
    def recognize_audio(self, audio_file):
        """识别音频文件"""
        # 1. 建立WebSocket连接
        ws = websocket.create_connection(self.create_auth_url())
        
        # 2. 发送音频数据
        with open(audio_file, 'rb') as f:
            while True:
                chunk = f.read(1280)  # 每次读取1280字节
                if not chunk:
                    break
                
                # 3. 构建数据包
                frame = {
                    "common": {"app_id": self.appid},
                    "business": {"language": "zh_cn", "domain": "iat"},
                    "data": {
                        "status": 1,  # 0:首帧 1:中间帧 2:尾帧
                        "format": "audio/L16;rate=16000",
                        "audio": base64.b64encode(chunk).decode(),
                        "encoding": "raw"
                    }
                }
                
                # 4. 发送数据并接收结果
                ws.send(json.dumps(frame))
                result = json.loads(ws.recv())
                
                # 5. 解析识别结果
                if result["code"] == 0:
                    self.parse_result(result)
        
        # 6. 关闭连接
        ws.close()
```

#### 关键技术点
1. **WebSocket管理：** 连接建立、心跳保持、异常重连
2. **音频分片：** 按固定大小分片传输，控制传输速率
3. **实时解析：** 边传输边解析，提高响应速度
4. **结果合并：** 将分片识别结果合并为完整文本
5. **时间对齐：** 根据音频时长生成SRT时间轴

#### 错误处理策略
- 网络断线重连
- API限流处理
- 音频格式不支持的回退方案
- 识别结果置信度过滤

---

### 3. 文本翻译模块 (Baidu_Text_transAPI.py)

#### 技术原理
集成百度翻译API，支持通用翻译和垂直领域翻译两种模式。

#### 实现技术
- **API提供商：** 百度翻译
- **通信协议：** HTTPS POST
- **认证方式：** MD5签名 + APPID
- **支持领域：** 11个专业领域

#### 具体实现逻辑
```python
def domain_translate(text, from_lang, to_lang, domain):
    """领域翻译实现"""
    # 1. 构建请求参数
    appid = config['baidu_appid']
    secret_key = config['baidu_appkey']
    salt = str(random.randint(32768, 65536))
    
    # 2. 生成签名
    sign_str = appid + text + salt + domain + secret_key
    sign = hashlib.md5(sign_str.encode('utf-8')).hexdigest()
    
    # 3. 构建请求体
    params = {
        'q': text,
        'from': from_lang,
        'to': to_lang,
        'appid': appid,
        'salt': salt,
        'domain': domain,  # 领域参数
        'sign': sign
    }
    
    # 4. 发送HTTP请求
    url = 'https://fanyi-api.baidu.com/api/trans/vip/fieldtranslate'
    response = requests.post(url, data=params)
    
    # 5. 解析响应
    result = response.json()
    if 'trans_result' in result:
        return result['trans_result'][0]['dst']
    else:
        # 错误处理：回退到通用翻译
        return general_translate(text, from_lang, to_lang)

def detect_language(text):
    """智能语言检测"""
    # 1. 使用正则表达式检测中文字符
    chinese_pattern = re.compile(r'[\u4e00-\u9fff]+')
    english_pattern = re.compile(r'[a-zA-Z]+')
    
    chinese_ratio = len(chinese_pattern.findall(text)) / len(text)
    english_ratio = len(english_pattern.findall(text)) / len(text)
    
    # 2. 根据比例判断主要语言
    if chinese_ratio > 0.3:
        return 'zh'
    elif english_ratio > 0.3:
        return 'en'
    else:
        return 'auto'  # 自动检测
```

#### 领域翻译支持
1. **it (信息技术)** - 程序、软件、硬件相关
2. **finance (金融)** - 银行、投资、保险相关
3. **machinery (机械)** - 工程、制造、设备相关
4. **senimed (生物医学)** - 医疗、药物、生物相关
5. **novel (网络文学)** - 小说、故事、文学相关
6. **academic (学术论文)** - 科研、论文、学术相关
7. **aerospace (航空航天)** - 航空、航天、军工相关
8. **wiki (人文社科)** - 历史、文化、社会相关
9. **news (新闻资讯)** - 新闻、报道、时事相关
10. **law (法律法规)** - 法律、法规、司法相关
11. **contract (合同)** - 合同、协议、商务相关

#### 智能策略
- 自动语言检测算法
- 混合语言分句处理
- 专业术语优化
- 翻译质量评估

---

### 4. 语音合成模块 (unified_speech_synthesis.py)

#### 技术原理
使用科大讯飞语音合成API，支持多发音人、多参数调节的高质量语音合成。

#### 实现技术
- **API提供商：** 科大讯飞 TTS
- **通信协议：** WebSocket
- **音频格式：** PCM/WAV
- **发音人数量：** 9种（5中文+4英文）

#### 具体实现逻辑
```python
class TTSWebSocket:
    def __init__(self, appid, api_key, api_secret):
        self.appid = appid
        self.api_key = api_key
        self.api_secret = api_secret
        self.ws_url = "wss://tts-api.xfyun.cn/v2/tts"
    
    def synthesize_speech(self, text, voice_type, speed, volume):
        """语音合成核心方法"""
        # 1. 建立WebSocket连接
        ws = websocket.create_connection(self.create_auth_url())
        
        # 2. 构建合成参数
        params = {
            "common": {"app_id": self.appid},
            "business": {
                "aue": "raw",  # 音频编码
                "auf": "audio/L16;rate=16000",  # 音频格式
                "vcn": voice_type,  # 发音人
                "speed": speed,     # 语速(0-100)
                "volume": volume,   # 音量(0-100)
                "pitch": 50,        # 音调
                "bgs": 0           # 背景音
            },
            "data": {
                "status": 2,  # 数据状态
                "text": base64.b64encode(text.encode()).decode()
            }
        }
        
        # 3. 发送合成请求
        ws.send(json.dumps(params))
        
        # 4. 接收音频数据
        audio_data = b''
        while True:
            result = json.loads(ws.recv())
            
            if result["code"] != 0:
                raise Exception(f"合成失败: {result['message']}")
            
            # 5. 解码音频数据
            if "data" in result and "audio" in result["data"]:
                audio_chunk = base64.b64decode(result["data"]["audio"])
                audio_data += audio_chunk
            
            # 6. 检查是否完成
            if result["data"]["status"] == 2:
                break
        
        # 7. 保存音频文件
        output_file = f"output_{int(time.time())}.wav"
        with open(output_file, 'wb') as f:
            f.write(audio_data)
        
        ws.close()
        return output_file
```

#### 发音人配置
**中文发音人：**
- xiaoyan (女声·亲和) - 自然亲切，适合日常对话
- aisjiuxu (男声·专业) - 成熟稳重，适合商务场景
- aisxping (男声·成熟) - 磁性声音，适合解说
- aisjinger (女声·温暖) - 温和甜美，适合教育
- aisbabyxu (童声·可爱) - 儿童声音，适合童话

**英文发音人：**
- x4_EnUs_Laura_education (女声·教育) - 标准美式发音
- x4_EnUs_Alex_education (男声·教育) - 清晰男声
- x4_EnUs_Emma_formal (女声·正式) - 正式场合
- x4_EnUs_Chris_formal (男声·正式) - 商务男声

#### 音频优化技术
1. **音频缓存：** 相同文本重复使用，提高效率
2. **质量控制：** 多级质量检测，确保输出质量
3. **并发处理：** 支持多段文本并行合成
4. **格式转换：** 自动转换为目标格式

---

### 5. 音频替换模块 (addNewSound.py)

#### 技术原理
使用FFmpeg实现视频音轨替换，支持音频时长调整和质量优化。

#### 实现技术
- **核心工具：** FFmpeg命令行
- **时长调整：** AudioTSM (Time-Scale Modification)
- **编码格式：** H.264视频 + AAC音频
- **质量控制：** CRF质量参数

#### 具体实现逻辑
```python
def replace_audio(video_path, new_audio_path, output_path):
    """音频替换主函数"""
    # 1. 检测视频和音频时长
    video_duration = get_video_duration(video_path)
    audio_duration = get_audio_duration(new_audio_path)
    
    # 2. 音频时长调整
    if abs(video_duration - audio_duration) > 0.5:  # 超过0.5秒差异
        adjusted_audio = adjust_audio_duration(
            new_audio_path, video_duration
        )
    else:
        adjusted_audio = new_audio_path
    
    # 3. 构建FFmpeg命令
    cmd = [
        'ffmpeg',
        '-i', video_path,           # 输入视频
        '-i', adjusted_audio,       # 输入音频
        '-c:v', 'copy',            # 复制视频流
        '-c:a', 'aac',             # 音频编码AAC
        '-b:a', '128k',            # 音频比特率
        '-map', '0:v:0',           # 映射视频流
        '-map', '1:a:0',           # 映射音频流
        '-shortest',               # 以最短流为准
        '-y',                      # 覆盖输出文件
        output_path
    ]
    
    # 4. 执行命令并监控进度
    process = subprocess.Popen(
        cmd, stdout=subprocess.PIPE, 
        stderr=subprocess.PIPE, text=True
    )
    
    # 5. 实时进度解析
    for line in process.stderr:
        if 'time=' in line:
            progress = parse_ffmpeg_progress(line, video_duration)
            yield progress  # 返回进度百分比
    
    # 6. 检查处理结果
    if process.returncode != 0:
        raise Exception("音频替换失败")

def adjust_audio_duration(audio_path, target_duration):
    """音频时长调整"""
    from audiotsm import wsola
    from audiotsm.io.wav import WavReader, WavWriter
    
    # 1. 计算时长比例
    current_duration = get_audio_duration(audio_path)
    ratio = target_duration / current_duration
    
    # 2. 使用WSOLA算法调整
    with WavReader(audio_path) as reader:
        with WavWriter(output_path, reader.channels, reader.samplerate) as writer:
            tsm = wsola(reader.channels, speed=ratio)
            tsm.run(reader, writer)
    
    return output_path
```

#### 关键技术点
1. **音视频同步：** 确保音频时长与视频匹配
2. **质量保持：** 使用copy模式避免视频重编码
3. **进度监控：** 解析FFmpeg输出显示实时进度
4. **错误恢复：** 检测失败并重试处理

#### 优化策略
- 预检查磁盘空间
- 使用硬件加速（NVENC/Quick Sync）
- 智能编码参数选择
- 临时文件管理

---

### 6. 字幕嵌入模块 (addSrt.py)

#### 技术原理
支持硬字幕烧录和软字幕轨道两种模式，提供丰富的字幕样式选项。

#### 实现技术
- **工具：** FFmpeg subtitles滤镜
- **格式支持：** SRT、VTT、ASS
- **样式控制：** 字体、大小、颜色、位置
- **编码：** UTF-8编码确保中文显示

#### 具体实现逻辑
```python
def embed_subtitles(video_path, subtitle_path, output_path, mode='hard'):
    """字幕嵌入主函数"""
    if mode == 'hard':
        return embed_hard_subtitles(video_path, subtitle_path, output_path)
    else:
        return embed_soft_subtitles(video_path, subtitle_path, output_path)

def embed_hard_subtitles(video_path, subtitle_path, output_path):
    """硬字幕烧录"""
    # 1. 字幕样式配置
    subtitle_style = (
        "FontName=Microsoft YaHei,"  # 字体
        "FontSize=24,"               # 字号
        "PrimaryColour=&H00FFFFFF,"  # 主要颜色（白色）
        "OutlineColour=&H00000000,"  # 边框颜色（黑色）
        "BackColour=&H80000000,"     # 背景颜色（半透明黑）
        "Bold=1,"                    # 粗体
        "Outline=2,"                 # 边框粗细
        "Shadow=1,"                  # 阴影
        "Alignment=2,"               # 底部居中对齐
        "MarginV=30"                 # 底部边距
    )
    
    # 2. 构建滤镜参数
    subtitle_filter = f"subtitles='{subtitle_path}':force_style='{subtitle_style}'"
    
    # 3. FFmpeg命令
    cmd = [
        'ffmpeg',
        '-i', video_path,
        '-vf', subtitle_filter,       # 视频滤镜
        '-c:a', 'copy',              # 复制音频
        '-c:v', 'libx264',           # 视频编码
        '-crf', '23',                # 质量参数
        '-preset', 'medium',         # 编码速度
        '-y',
        output_path
    ]
    
    return execute_ffmpeg_command(cmd)

def embed_soft_subtitles(video_path, subtitle_path, output_path):
    """软字幕嵌入"""
    cmd = [
        'ffmpeg',
        '-i', video_path,
        '-i', subtitle_path,
        '-c:v', 'copy',              # 复制视频流
        '-c:a', 'copy',              # 复制音频流
        '-c:s', 'mov_text',          # 字幕编码
        '-map', '0:v',               # 映射视频
        '-map', '0:a',               # 映射音频
        '-map', '1:s',               # 映射字幕
        '-disposition:s:0', 'default', # 设为默认字幕
        '-y',
        output_path
    ]
    
    return execute_ffmpeg_command(cmd)

def create_bilingual_subtitle(original_srt, translated_srt, output_srt):
    """创建双语字幕"""
    # 1. 解析两个字幕文件
    original_subs = parse_srt_file(original_srt)
    translated_subs = parse_srt_file(translated_srt)
    
    # 2. 合并字幕内容
    bilingual_subs = []
    for i, (orig, trans) in enumerate(zip(original_subs, translated_subs)):
        bilingual_sub = {
            'index': i + 1,
            'start': orig['start'],
            'end': orig['end'],
            'text': f"{orig['text']}\n{trans['text']}"  # 双行显示
        }
        bilingual_subs.append(bilingual_sub)
    
    # 3. 生成SRT文件
    write_srt_file(bilingual_subs, output_srt)
    return output_srt
```

#### 字幕样式配置
1. **字体选择：** 微软雅黑、思源黑体等中文友好字体
2. **大小调节：** 根据视频分辨率自动调整
3. **颜色方案：** 白字黑边，确保可读性
4. **位置控制：** 底部居中，避免遮挡重要内容
5. **特效支持：** 阴影、边框、渐变等效果

#### 高级功能
- 字幕时间轴自动对齐
- 多语言字幕混合
- 字幕样式模板系统
- 批量字幕处理

---

## 系统集成与优化

### 线程管理
```python
class ProcessThread(QThread):
    """主处理线程"""
    def run(self):
        try:
            # 1. 音频提取
            self.update_progress(10, "正在提取音频...")
            audio_file = extract_audio(self.video_path)
            
            # 2. 语音识别
            self.update_progress(30, "正在识别语音...")
            text_result = recognize_speech(audio_file)
            
            # 3. 文本翻译
            if self.need_translation:
                self.update_progress(50, "正在翻译文本...")
                translated_text = translate_text(text_result)
            
            # 4. 语音合成
            self.update_progress(70, "正在合成语音...")
            new_audio = synthesize_speech(translated_text)
            
            # 5. 音频替换
            self.update_progress(85, "正在替换音频...")
            output_video = replace_audio(self.video_path, new_audio)
            
            # 6. 字幕嵌入
            if self.embed_subtitle:
                self.update_progress(95, "正在嵌入字幕...")
                final_video = embed_subtitles(output_video, subtitle_file)
            
            self.update_progress(100, "处理完成！")
            
        except Exception as e:
            self.error_occurred.emit(str(e))
```

### 错误处理机制
1. **网络错误：** 自动重试机制
2. **API限制：** 智能限流和队列管理
3. **文件错误：** 格式检测和转换
4. **内存不足：** 分片处理和资源回收

### 性能优化
1. **并发处理：** 多线程加速处理流程
2. **缓存机制：** 避免重复计算和请求
3. **预处理：** 提前验证和准备资源
4. **增量更新：** 只处理变更部分

这套系统通过模块化设计、错误处理、性能优化等多方面技术手段，实现了高效、稳定的视频语音转换功能。 